{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f07a5b",
   "metadata": {},
   "source": [
    "# CI / CD with CML API V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec2c717",
   "metadata": {},
   "source": [
    "##### Cloudera Machine Learning exposes a REST API that you can use to perform operations related to projects, jobs, and runs. You can use API commands to integrate CML with third-party workflow tools or to control CML from the command line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfcd355",
   "metadata": {},
   "source": [
    "##### This notebook demonstrates how to create and execute three CML jobs with the CML API V2. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a70956",
   "metadata": {},
   "source": [
    "For the Public Documentation please visit this [page](https://docs.cloudera.com/machine-learning/cloud/api/topics/ml-api-v2.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b5b10",
   "metadata": {},
   "source": [
    "For a full example of the API's capabilities, please visit this notebook from [Cloudera's Public GitHub](https://github.com/cloudera/CML_AMP_APIv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfcca62",
   "metadata": {},
   "source": [
    "#### To use the Python API in your own code, first install the Python API client and point it to your cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "784c14e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install the API\n",
    "\n",
    "import os\n",
    "cluster = os.getenv(\"CDSW_DOMAIN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1362390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nnkkke'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cmlapi.utils import Cursor\n",
    "import cmlapi\n",
    "import string\n",
    "import random\n",
    "import json\n",
    "\n",
    "try:\n",
    "    client = cmlapi.default_client()\n",
    "except ValueError:\n",
    "    print(\"Could not create a client. If this code is not being run in a CML session, please include the keyword arguments \\\"url\\\" and \\\"cml_api_key\\\".\")\n",
    "\n",
    "session_id = \"\".join([random.choice(string.ascii_lowercase) for _ in range(6)])\n",
    "session_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4037c97",
   "metadata": {},
   "source": [
    "##### The API has a lot of cool features. For example, it allows you to view all runtimes associated with the CML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311e842e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aakulov1/cml-zeppelin-runtime:1.0.1\n",
      "docker.io/cvandyke/automl_pycaret:1.7\n",
      "docker.io/cvandyke/automl_pycaret:1.8\n",
      "docker.io/cvandyke/enhancedjupyterlab:1.0\n",
      "docker.io/cvandyke/enhancedjupyterlab:1.1\n",
      "docker.io/cvandyke/enhancedjupyterlab:1.2\n",
      "docker.io/cvandyke/python3.7-java11:1.1\n",
      "docker.io/cvandyke/python3.7-java11:1.2\n",
      "docker.io/cvandyke/rstudio:2022.04.9\n",
      "docker.io/cvandyke/rstudio-cloudera-runtime:2022.04.10\n",
      "docker.io/cvandyke/rstudio-cloudera-runtime-cpv:2022.12.1\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.7-cuda:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.7-cuda:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.7-cuda:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.7-rapids:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.7-standard:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.7-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.7-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.8-cuda:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.8-cuda:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.8-cuda:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.8-rapids:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.8-standard:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.8-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.8-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.9-cuda:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.9-cuda:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.9-cuda:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.9-standard:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.9-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-jupyterlab-python3.9-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.7-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.7-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.8-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-python3.9-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-r3.6-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-r4.0-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-pbj-workbench-r4.1-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.7-cuda:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.7-cuda:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.7-cuda:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.7-rapids:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.7-standard:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.7-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.7-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.8-cuda:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.8-cuda:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.8-cuda:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.8-rapids:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.8-standard:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.8-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.8-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.9-cuda:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.9-cuda:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.9-cuda:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.9-standard:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.9-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.9-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-r3.6-standard:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-r3.6-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-r3.6-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-r4.0-standard:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-r4.0-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-r4.0-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-r4.1-standard:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-r4.1-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-r4.1-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-scala2.11-standard:2021.12.1-b17\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-scala2.11-standard:2022.04.1-b6\n",
      "docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-scala2.11-standard:2022.11.1-b2\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:6.3.7-b38\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:6.4.0-b12\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:6.4.1-b7\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:6.4.2-b13\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:6.4.3-b33\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:7.0.0-b24\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:7.0.1-b28\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:7.0.2-b35\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:7.0.2-b46\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:7.0.3-b57\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:7.0.4-b38\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:7.0.4-b41\n",
      "docker.repository.cloudera.com/cloudera/cdv/runtimedataviz:7.0.5-b53\n",
      "ghcr.io/fletchjeff/cml_rstudio_1.4:2021.09.3\n",
      "ghcr.io/oliviermeignan/jupyterlabgit:2022.05.4-b3\n",
      "ghcr.io/oliviermeignan/rstudio_1.2:2022.08.1-b1\n",
      "ghcr.io/oliviermeignan/vscode:2022.03.1\n",
      "pauldefusco/arpad_custom_1\n",
      "pauldefusco/arpad_custom_3\n",
      "pauldefusco/brian_custom_3\n",
      "pauldefusco/brian_custom_7\n",
      "pauldefusco/brian_custom_container_1\n",
      "pauldefusco/cml_bees_jupyter:latest\n",
      "pauldefusco/cml_bees:latest\n",
      "pauldefusco/rjava_runtime\n",
      "peterableda/rstudio-cloudera-runtime:2022.04-8\n",
      "public.ecr.aws/d7w2o6p0/dbt-cml:1.1.10\n",
      "zelkey/cml-dist-torch:1.0-cuda11.1\n"
     ]
    }
   ],
   "source": [
    "# cursor also supports search_filter\n",
    "# cursor = Cursor(client.list_runtimes, \n",
    "#                 search_filter = json.dumps({\"image_identifier\":\"jupyter\"}))\n",
    "cursor = Cursor(client.list_runtimes)\n",
    "runtimes = cursor.items()\n",
    "for rt in runtimes:\n",
    "    print(rt.image_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "761df8e9-f24b-4700-ab9e-34e1ba74f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'next_page_token': '',\n",
      " 'runtime_addons': [{'component': 'HadoopCLI',\n",
      "                     'created_at': datetime.datetime(2022, 5, 26, 15, 28, 57, 53302, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.10 - HOTFIX-1',\n",
      "                     'id': 4,\n",
      "                     'identifier': 'hadoop-cli-7.2.10-hf1',\n",
      "                     'manageable': False,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'DELETED'},\n",
      "                    {'component': 'HadoopCLI',\n",
      "                     'created_at': datetime.datetime(2022, 10, 21, 19, 4, 43, 251587, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.10 - HOTFIX-1 JAVA '\n",
      "                                     '8U342',\n",
      "                     'id': 10,\n",
      "                     'identifier': 'hadoop-cli-7.2.10-hf1-j8u342',\n",
      "                     'manageable': False,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'HadoopCLI',\n",
      "                     'created_at': datetime.datetime(2022, 5, 26, 15, 28, 56, 937930, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.11 - HOTFIX-4',\n",
      "                     'id': 2,\n",
      "                     'identifier': 'hadoop-cli-7.2.11-hf4',\n",
      "                     'manageable': False,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'DELETED'},\n",
      "                    {'component': 'HadoopCLI',\n",
      "                     'created_at': datetime.datetime(2022, 10, 21, 19, 4, 43, 355788, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.11 - HOTFIX-4 JAVA '\n",
      "                                     '8U342',\n",
      "                     'id': 13,\n",
      "                     'identifier': 'hadoop-cli-7.2.11-hf4-j8u342',\n",
      "                     'manageable': False,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'HadoopCLI',\n",
      "                     'created_at': datetime.datetime(2022, 6, 3, 21, 18, 33, 117810, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.14',\n",
      "                     'id': 8,\n",
      "                     'identifier': 'hadoop-cli-7.2.14',\n",
      "                     'manageable': False,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'DELETED'},\n",
      "                    {'component': 'HadoopCLI',\n",
      "                     'created_at': datetime.datetime(2022, 10, 21, 19, 4, 43, 319555, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.14 - JAVA 8U342',\n",
      "                     'id': 12,\n",
      "                     'identifier': 'hadoop-cli-7.2.14-j8u342',\n",
      "                     'manageable': False,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'HadoopCLI',\n",
      "                     'created_at': datetime.datetime(2022, 5, 26, 15, 28, 57, 667, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.8 - HOTFIX-1',\n",
      "                     'id': 3,\n",
      "                     'identifier': 'hadoop-cli-7.2.8-hf1',\n",
      "                     'manageable': False,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'DELETED'},\n",
      "                    {'component': 'HadoopCLI',\n",
      "                     'created_at': datetime.datetime(2022, 10, 21, 19, 4, 43, 214860, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Hadoop CLI - CDP 7.2.8 - HOTFIX-1 JAVA '\n",
      "                                     '8U342',\n",
      "                     'id': 9,\n",
      "                     'identifier': 'hadoop-cli-7.2.8-hf1-j8u342',\n",
      "                     'manageable': False,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'Spark',\n",
      "                     'created_at': datetime.datetime(2022, 5, 26, 15, 28, 57, 98026, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Spark 2.4.7 - CDP 7.2.11 - CDE 1.13 - '\n",
      "                                     'HOTFIX-2',\n",
      "                     'id': 5,\n",
      "                     'identifier': 'spark247-13-hf2',\n",
      "                     'manageable': True,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'Spark',\n",
      "                     'created_at': datetime.datetime(2022, 6, 3, 21, 18, 32, 961613, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Spark 2.4.8 - CDE 1.15 - HOTFIX-1',\n",
      "                     'id': 6,\n",
      "                     'identifier': 'spark248-15-hf1',\n",
      "                     'manageable': True,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'Spark',\n",
      "                     'created_at': datetime.datetime(2023, 1, 4, 9, 21, 44, 174421, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Spark 2.4.8 - CDE 1.17 - HOTFIX-1',\n",
      "                     'id': 14,\n",
      "                     'identifier': 'spark248-17-hf1',\n",
      "                     'manageable': True,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'Spark',\n",
      "                     'created_at': datetime.datetime(2022, 5, 26, 15, 28, 56, 864246, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Spark 3.1.1 - CDP 7.2.11 - CDE 1.13 - '\n",
      "                                     'HOTFIX-2',\n",
      "                     'id': 1,\n",
      "                     'identifier': 'spark311-13-hf2',\n",
      "                     'manageable': True,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'Spark',\n",
      "                     'created_at': datetime.datetime(2022, 6, 3, 21, 18, 33, 11359, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Spark 3.2.0 - CDE 1.15 - HOTFIX-1',\n",
      "                     'id': 7,\n",
      "                     'identifier': 'spark320-15-hf1',\n",
      "                     'manageable': True,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'DELETED'},\n",
      "                    {'component': 'Spark',\n",
      "                     'created_at': datetime.datetime(2022, 10, 21, 19, 4, 43, 284717, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Spark 3.2.0 - CDE 1.15 - HOTFIX-2',\n",
      "                     'id': 11,\n",
      "                     'identifier': 'spark320-15-hf2',\n",
      "                     'manageable': True,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'AVAILABLE'},\n",
      "                    {'component': 'Spark',\n",
      "                     'created_at': datetime.datetime(2023, 1, 4, 9, 21, 44, 220206, tzinfo=tzlocal()),\n",
      "                     'display_name': 'Spark 3.2.0 - CDE 1.17 - HOTFIX-1',\n",
      "                     'id': 15,\n",
      "                     'identifier': 'spark320-17-hf1',\n",
      "                     'manageable': True,\n",
      "                     'reason': 'PodCompleted: ',\n",
      "                     'status': 'AVAILABLE'}]}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import cmlapi\n",
    "from cmlapi.rest import ApiException\n",
    "from pprint import pprint\n",
    "\n",
    "try:\n",
    "    # List the available runtime addons, optionally filtered, sorted, and paginated.\n",
    "    api_response = client.list_runtime_addons(page_size=500)\n",
    "    pprint(api_response)\n",
    "except ApiException as e:\n",
    "    print(\"Exception when calling CMLServiceApi->list_runtime_addons: %s\\n\" % e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15403f5",
   "metadata": {},
   "source": [
    "##### Similarly, you can see all jobs in the current CML Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "919557ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched 0 jobs from the project\n"
     ]
    }
   ],
   "source": [
    "### GET ALL PREVIOUS JOBS FROM PROJECT ###\n",
    "    \n",
    "project_id = os.environ[\"CDSW_PROJECT_ID\"]\n",
    "\n",
    "joblists = client.list_jobs(project_id = project_id)\n",
    "print(f'Fetched {len(joblists.jobs)} jobs from the project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1b731c9-3830-411d-ab78-968577064ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f96y-7e2i-xb6z-6suc'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b883bc",
   "metadata": {},
   "source": [
    "## You can build ML Ops Pipelines by creating and executing CML Jobs with the API from this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8c082",
   "metadata": {},
   "source": [
    "##### First we create a CML Job to train a model. We trained this model in ProtoType.py but in a real world scenario you may have created your model baseline with ML Flow, also available in CML under the Experiments tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05f30d32-0327-4b85-bea8-c954e4ad6bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cdsw/02_APIv2_Pipeline\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e548672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE A JOB TO RETRAIN THE MODEL ###\n",
    "    \n",
    "# Create a job. We will create dependent/children jobs of this job, so we call this one a \"grandparent job\". The parameter \"runtime_identifier\" is needed if this is running in a runtimes project.\n",
    "monitoring_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"MonitoringJob\",\n",
    "    script = \"02_APIv2_Pipeline/01_Pipeline_MonitoringJob.py\",\n",
    "    cpu = 4.0,\n",
    "    memory = 12.0,\n",
    "    runtime_identifier = \"docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.7-standard:2022.11.1-b2\", \n",
    "    runtime_addon_identifiers = [\"spark311-13-hf1\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fb52c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create this job within the project specified by the project_id parameter.\n",
    "monitoring_job = client.create_job(monitoring_job_body, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964ec40a",
   "metadata": {},
   "source": [
    "##### A second CML Job to push the model to a REST Endpoint can be set to execute as a dependency on the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0428839",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE A JOB TO PUSH THE MODEL TO A REST ENDPOINT ###\n",
    "\n",
    "# Create a dependent job by specifying the parent job's ID in the parent_job_id field.\n",
    "training_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"TrainingJob\",\n",
    "    script = \"02_APIv2_Pipeline/02_Pipeline_TrainModelJob.py\",\n",
    "    kernel = \"python3\",\n",
    "    cpu = 2,\n",
    "    memory = 4,\n",
    "    runtime_identifier = \"docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.7-standard:2022.11.1-b2\",\n",
    "    runtime_addon_identifiers = [\"spark311-13-hf1\"]\n",
    ")\n",
    "training_job = client.create_job(training_job_body, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f89adb0-5eae-4f95-bddd-6ae40b6e8124",
   "metadata": {},
   "source": [
    "##### A third CML Job to push the model to a REST Endpoint can be set to execute as a dependency on Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5608a267",
   "metadata": {},
   "outputs": [],
   "source": [
    "### CREATE A JOB TO DO INFERENCE ON THE MODEL ###\n",
    "\n",
    "# Create a job that is dependent on the job from the previous cell. This leads to a dependency chain of grandparent_job -> parent_job -> child_job. If grantparent_job runs and succeeds, then parent_job will trigger, and if parent_job runs and succeeds, child_job will trigger. This one uses a template script that does not terminate, so we'll have the opportunity to try stopping it later.\n",
    "deploymodel_job_body = cmlapi.CreateJobRequest(\n",
    "    project_id = project_id,\n",
    "    name = \"DeployModelJob\",\n",
    "    script = \"02_APIv2_Pipeline/03_Pipeline_DeployModelJob.py\",\n",
    "    kernel = \"python3\",\n",
    "    cpu = 4,\n",
    "    memory = 12,  \n",
    "    runtime_identifier = \"docker.repository.cloudera.com/cloudera/cdsw/ml-runtime-workbench-python3.7-standard:2022.11.1-b2\",\n",
    "    runtime_addon_identifiers = [\"spark311-13-hf1\"],\n",
    "    parent_job_id = training_job.id\n",
    ")\n",
    "deploymodel_job = client.create_job(deploymodel_job_body, project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28475ba1",
   "metadata": {},
   "source": [
    "##### Notice that although we have created the jobs, we haven't executed them yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae338ba9",
   "metadata": {},
   "source": [
    "##### If you hover over to the CML Project landing page and open the Jobs tab you will notice the jobs have been added under the \"Jobs Section\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b85d21",
   "metadata": {},
   "source": [
    "![title](images/cml-jobs-created.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcd075b",
   "metadata": {},
   "source": [
    "##### Next, we can use the API to run the first job. When it succeeds, the second job will execute, and then the third..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07ca2deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a job run for the specified job.\n",
    "# If the job has dependent jobs, the dependent jobs will run after the job succeeds.\n",
    "# In this case, the grandparent job will run first, then the parent job, and then the child job, provided each job run succeeds.\n",
    "jobrun_body = cmlapi.CreateJobRunRequest(project_id, monitoring_job.id)\n",
    "job_run = client.create_job_run(jobrun_body, project_id, monitoring_job.id)\n",
    "run_id = job_run.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae7ba1",
   "metadata": {},
   "source": [
    "##### Go back to the Jobs tab in the CML landing page. Notice the jobs are now executing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27364632",
   "metadata": {},
   "source": [
    "![title](images/cml-jobs-running.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec496129",
   "metadata": {},
   "source": [
    "##### If you want to learn more about CML Jobs, you can click on the CML Job and four new tabs will open, giving you the ability to explore the Job DAG, look into execution, and even determine where in your code errors occurred if any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c392342",
   "metadata": {},
   "source": [
    "![title](images/cml-job-dependencies.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e0698",
   "metadata": {},
   "source": [
    "![title](images/cml-job-history.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b680e739",
   "metadata": {},
   "source": [
    "![title](images/cml-job-troubleshoot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c05ffed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
